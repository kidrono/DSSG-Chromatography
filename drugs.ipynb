{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "import seaborn; seaborn.set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Peaks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_sample_graph(path_to_tic_front, true_peaks=None):\n",
    "    \"\"\"\n",
    "    creating a plot of the sample, with the possibility of showing the peaks highlighted by red dot\n",
    "    :param path_to_tic_front: the path to the sample tic_front file\n",
    "    :param true_peaks: list of peaks to add to the plot (if its none, there will be normal plot)\n",
    "    \"\"\"\n",
    "    sample_df = pd.read_csv(path_to_tic_front, names=['time', 'value']).iloc[1:]\n",
    "    sample_df.value.plot(figsize=(15,8), alpha=.3)\n",
    "    if true_peaks is not None:\n",
    "        sample_df.iloc[true_peaks].value.plot(style='.', lw=10, color='red')\n",
    "    title_name = path_to_tic_front.split('/')\n",
    "    plt.title(title_name[2] + \"_\" + title_name[3])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def find_peaks(tic_front_path, plot=False, threshold_factor=4):\n",
    "    \"\"\"\n",
    "    finding the peaks of chromatography\n",
    "    :param tic_front_path: full path of the tic front file to analyze\n",
    "    :param plot: boolean - True if you want to plot the graph with the peaks\n",
    "    :param threshold_factor: larger threshold factor will cause to function to be more sensitive to local peaks\n",
    "    :return: filtered_iloc_max - list of the indexes of the peaks, df1 - the dataframe of the chromatography.\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(tic_front_path, names=['time', 'value']).iloc[1:]\n",
    "    ilocs_max = argrelextrema(df1.value.values, np.greater_equal, order=10)[0]\n",
    "    if len(ilocs_max) > 0:\n",
    "        if ilocs_max[0] == 0:\n",
    "            ilocs_max = ilocs_max[1:]\n",
    "    iloc_max_list = list(ilocs_max)\n",
    "    df_median = df1['value'][ilocs_max].median()\n",
    "    max_val = df1['value'][ilocs_max].max()\n",
    "    threshold_factor = max_val ** (1 / threshold_factor) / 2\n",
    "    filtered_iloc_max = list(filter(lambda x: df1['value'][x] > df_median * threshold_factor, iloc_max_list))\n",
    "    # plot the chromatography with the peaks\n",
    "    if plot:\n",
    "        plot_sample_graph(tic_front_path, filtered_iloc_max)\n",
    "    return filtered_iloc_max, df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_hfb(peaks_indices, sample_df, method):\n",
    "    epsilon = 0.1\n",
    "    hfb_points = []\n",
    "    if method == \"DRUG-AUTO.M\":\n",
    "        hfb_points = [(2.8, 3.8), (2.3, 2.9), (4.2, 4.5), (2.5, 2.95)]\n",
    "    if method == \"PO-AUTO.M\":\n",
    "        hfb_points = [(5.2, 6.2), (4.8, 5.3), (4.9, 5.5), (2.9, 4.1), (3.3, 4.7)]\n",
    "    for pair in hfb_points:\n",
    "        first_hfb = False\n",
    "        second_hfb = False\n",
    "        for index in peaks_indices:\n",
    "            if pair[0] - epsilon < float(sample_df['time'][index]) < pair[0] + epsilon:\n",
    "                first_hfb = index\n",
    "            if pair[1] - epsilon < float(sample_df['time'][index]) < pair[1] + epsilon:\n",
    "                second_hfb = index\n",
    "        if first_hfb and second_hfb:\n",
    "            peaks_indices.remove(second_hfb)\n",
    "            return peaks_indices\n",
    "    return peaks_indices\n",
    "\n",
    "\n",
    "def is_HFB(path_to_file):\n",
    "    # Using readline()\n",
    "    file1 = open(path_to_file[1:] + 'runstart.txt', 'r')\n",
    "    string_to_find = \"HFB\"\n",
    "    while True:\n",
    "\n",
    "        # Get next line from file\n",
    "        line = file1.readline()\n",
    "\n",
    "        # if line is empty\n",
    "        # end of file is reached\n",
    "        if not line:\n",
    "            break\n",
    "        if string_to_find in line:\n",
    "            file1.close()\n",
    "            return True\n",
    "    file1.close()\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def df_for_method(method_name, x_axis_times=False):\n",
    "    methods_dict = pd.read_csv(\"df_dic.csv\")\n",
    "    methods_dict.drop(methods_dict.columns[0], axis=1, inplace=True)\n",
    "    method_df = pd.DataFrame()\n",
    "    real_samples = 0\n",
    "    for sample in methods_dict[method_name].to_list():\n",
    "        if sample == '-1':\n",
    "            break\n",
    "        real_samples += 1\n",
    "    method_df[\"sample\"] = methods_dict[method_name][0:real_samples]\n",
    "    sample_list = method_df['sample'].to_list()\n",
    "    samples = 0\n",
    "    num_of_peaks = []\n",
    "    peak_locations = []\n",
    "    peak_values = []\n",
    "    for sample in sample_list:\n",
    "        # print(sample)\n",
    "        tic_front_path = sample[1:] + 'tic_front.csv'\n",
    "        # print(tic_front_path)\n",
    "        peaks, df = find_peaks(tic_front_path)\n",
    "        if method_name == \"DRUG-AUTO.M\" or method_name == 'PO-AUTO.M':\n",
    "            if is_HFB(sample):\n",
    "                peaks_hfb = filter_hfb(peaks, df, method_name)\n",
    "                peaks = peaks_hfb\n",
    "        num_of_peaks.append(len(peaks))\n",
    "        if x_axis_times:\n",
    "            peak_locations.append(df['time'][peaks].values)\n",
    "        else:\n",
    "            peak_locations.append(peaks)\n",
    "        peak_values.append(df['value'][peaks].values)\n",
    "        samples += 1\n",
    "    method_df[\"num_of_peaks\"] = num_of_peaks\n",
    "    peak1_index = []\n",
    "    peak1_value = []\n",
    "    peak2_index = []\n",
    "    peak2_value = []\n",
    "    peak3_index = []\n",
    "    peak3_value = []\n",
    "    peak4_index = []\n",
    "    peak4_value = []\n",
    "    peak5_index = []\n",
    "    peak5_value = []\n",
    "    peak6_index = []\n",
    "    peak6_value = []\n",
    "    new_columns = [(peak1_index, peak1_value), (peak2_index, peak2_value), (peak3_index, peak3_value),\n",
    "                   (peak4_index, peak4_value), (peak5_index, peak5_value), (peak6_index, peak6_value)]\n",
    "    for i in range(6):\n",
    "        # print(new_columns[i][0])\n",
    "        for j in range(samples):\n",
    "            if len(peak_locations[j]) > i:\n",
    "                new_columns[i][0].append(peak_locations[j][i])\n",
    "            else:\n",
    "                new_columns[i][0].append(-1)\n",
    "            if len(peak_values[j]) > i:\n",
    "                new_columns[i][1].append(peak_values[j][i])\n",
    "            else:\n",
    "                new_columns[i][1].append(-1)\n",
    "    for i in range(6):\n",
    "        col_name = \"peak_\" + str(i + 1) + \"_index\"\n",
    "        method_df[col_name] = new_columns[i][0]\n",
    "        col_name = \"peak_\" + str(i + 1) + \"_value\"\n",
    "        method_df[col_name] = new_columns[i][1]\n",
    "    return method_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drug_auto_df = df_for_method(\"DRUG-AUTO.M\", x_axis_times=True)\n",
    "# drug_auto_df.to_csv(\"drug_auto_updated.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one_df = pd.DataFrame()\n",
    "two_df = pd.DataFrame()\n",
    "three_df = pd.DataFrame()\n",
    "four_df = pd.DataFrame()\n",
    "five_df = pd.DataFrame()\n",
    "dfs = [one_df, two_df, three_df, four_df, five_df]\n",
    "\n",
    "for i in range(5):\n",
    "    dfs[i] = drug_auto_df[drug_auto_df['num_of_peaks'] == i + 1]\n",
    "    dfs[i] = dfs[i].drop([col for col in dfs[i].columns if dfs[i][col].eq(-1).any()], axis=1)\n",
    "    dfs[i] = dfs[i].loc[:, dfs[i].columns != 'num_of_peaks']\n",
    "\n",
    "\n",
    "# for i in range(len(dfs)):\n",
    "#     name = 'drug_auto_' + str(i+1) + '_peaks.csv'\n",
    "#     dfs[i].to_csv(name)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    for j in range(i):\n",
    "        name = 'difference_' + str(j+1)\n",
    "        peak1 = 'peak_' + str(j+1) + '_index'\n",
    "        peak2 = 'peak_' + str(j+2) + '_index'\n",
    "        dfs[i][name] = dfs[i][peak2] - dfs[i][peak1]\n",
    "\n",
    "\n",
    "\n",
    "# dfs[1]['difference'] = dfs[1]['peak_2_index'] - dfs[1]['peak_1_index']\n",
    "# print(dfs[1]['peak_2_index'])\n",
    "def scale_data(df):\n",
    "  for col in df.columns:\n",
    "    df[col] = absolute_maximum_scale(df[col])\n",
    "  return df\n",
    "\n",
    "\n",
    "def absolute_maximum_scale(series):\n",
    "    return series / series.max()\n",
    "\n",
    "# cols_for_norm = dfs[1][['peak_1_value','peak_2_value']].transpose()\n",
    "# cols_for_norm=scale_data(cols_for_norm).transpose()\n",
    "#\n",
    "# dfs[1]['peak_1_value']=cols_for_norm['peak_1_value']\n",
    "# dfs[1]['peak_2_value']=cols_for_norm['peak_2_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# new_df = dfs[1].loc[:, dfs[1].columns != 'sample']\n",
    "# new_df = dfs[1]['difference'].values.reshape(-1, 1)\n",
    "# new_df = dfs[1][['peak_1_index','difference_1']]\n",
    "# clustering = cluster.KMeans(n_clusters=32)\n",
    "# fitted_data = clustering.fit_predict(new_df)\n",
    "# dfs[1]['cluster_omer'] = fitted_data\n",
    "# dfs[1].to_csv('drug_auto_2_peaks.csv')\n",
    "\n",
    "new_df = dfs[2][['peak_1_index','difference_1', 'difference_2']]\n",
    "clustering = cluster.KMeans(n_clusters=32)\n",
    "fitted_data = clustering.fit_predict(new_df)\n",
    "dfs[2]['cluster_omer'] = fitted_data\n",
    "# dfs[2].to_csv('drug_auto_3_peaks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# printing examples of the basic cluster\n",
    "# index = 0\n",
    "# for sample in dfs[1]['sample'].to_list():\n",
    "#     tic_front_path = sample[1:] + 'tic_front.csv'\n",
    "#     if fitted_data[index] == 8:\n",
    "#         if index < 550:\n",
    "#             find_peaks(tic_front_path, True)\n",
    "#             plt.show()\n",
    "#     index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_samples_from_same_cluster(df, cluster_number):\n",
    "    plots = 0\n",
    "    relevant_samples = df[df['cluster_omer'] == cluster_number]\n",
    "    print(\"number of samples in cluster \" + str(cluster_number) + \": \" + str(len(relevant_samples)))\n",
    "    for sample in relevant_samples['sample'].to_list():\n",
    "        tic_front_path = sample[1:] + 'tic_front.csv'\n",
    "        if plots < 7:\n",
    "            # find_peaks(tic_front_path, True)\n",
    "            data = pd.read_csv(tic_front_path, names=['x', 'y']).iloc[1:]\n",
    "            title_name = sample[1:].split('/')\n",
    "            title_ = \"cluster: \" + str(cluster_number) + \", sample: \" + title_name[2] + \"/\" + title_name[3]\n",
    "            data.plot(x='x', y='y', title=title_)\n",
    "            file_name = \"clusters_plot_omer/cluster_\" + str(cluster_number) + \"_graph_\" + str(plots) + \".png\"\n",
    "            # plt.savefig(file_name)\n",
    "            plt.show()\n",
    "        plots += 1\n",
    "\n",
    "# plot_samples_from_same_cluster(three_peaks_df, 18)\n",
    "\n",
    "# for i in range(32):\n",
    "#     plot_samples_from_same_cluster(two_peaks_df, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "two_peaks_df = pd.read_csv('drug_auto_2_peaks.csv')\n",
    "three_peaks_df = pd.read_csv('drug_auto_3_peaks.csv')\n",
    "\n",
    "index_list = []\n",
    "for i in range(len(two_peaks_df)):\n",
    "    if i % 7 == 0:\n",
    "        index_list.append(i)\n",
    "#\n",
    "index_list = index_list[:50]\n",
    "\n",
    "matrix_df = two_peaks_df.iloc[index_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "omer_cluster_matrix = []\n",
    "yaara_clusters = [13, 11, 2, 14, 14, 12, 2, 5, 14, 7, 15, 13, 2, 13, 7, 14, 2, 8, 13, 2, 9, 2, 15, 2,\n",
    "                  2, 16, 2, 14, 2, 13, 7, 15, 2, 13, 11, 10, 7, 7, 6, 17, 1, 1, 4, 1, 3, 2, 3, 1, 18, 19]\n",
    "yaara_cluster_matrix = []\n",
    "noam_clusters = [3, 9, 10, 19, 20, 5, 13, 22, 16, 29, 27, 1, 12, 2, 28, 16, 7, 23, 2, 10, 14, 6, 17, 8, 10, 26, 11,\n",
    "                 21, 7, 1, 29, 18, 7, 4, 9, 4, 29, 29, 33, 30, 32, 32, 15, 31, 24, 10, 25, 31, 0, 34]\n",
    "noam_cluster_matrix = []\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    line = []\n",
    "    for j in range(50):\n",
    "        if yaara_clusters[i] == yaara_clusters[j]:\n",
    "            line.append(1)\n",
    "        else:\n",
    "            line.append(0)\n",
    "    yaara_cluster_matrix.append(line)\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    line = []\n",
    "    for j in range(50):\n",
    "        if noam_clusters[i] == noam_clusters[j]:\n",
    "            line.append(1)\n",
    "        else:\n",
    "            line.append(0)\n",
    "    noam_cluster_matrix.append(line)\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    line = []\n",
    "    for j in range(50):\n",
    "        if matrix_df['cluster_omer'][index_list[i]] == matrix_df['cluster_omer'][index_list[j]]:\n",
    "            line.append(1)\n",
    "        else:\n",
    "            line.append(0)\n",
    "    omer_cluster_matrix.append(line)\n",
    "\n",
    "\n",
    "samples_matrix = []\n",
    "\n",
    "for i in range(50):\n",
    "    line = []\n",
    "    for j in range(50):\n",
    "        line.append((matrix_df['sample'][index_list[i]], matrix_df['sample'][index_list[j]]))\n",
    "    samples_matrix.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 ... 0 0 0]\n",
      " [0 3 1 ... 0 0 0]\n",
      " [0 1 3 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 3]]\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/01-2022/10-01/1014/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/01-2022/03-01/1099/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/01-2022/18-01/1081/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/01-2022/20-01/1041/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/01-2022/23-01/1011/', '/MS data DSSG/01-2022/03-01/1076/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/24-02/1017/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/04-02/1017/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/04-02/1054/', '/MS data DSSG/01-2022/02-01/1044/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/04-02/1054/', '/MS data DSSG/01-2022/02-01/1047/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/04-02/1054/', '/MS data DSSG/01-2022/09-01/1019/')\n",
      "noam: 0 yaara: 1 omer: 0\n",
      "('/MS data DSSG/02-2022/04-02/1054/', '/MS data DSSG/01-2022/05-01/1042/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/04-02/1054/', '/MS data DSSG/01-2022/20-01/1027/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/10-02/1002/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/10-02/1032/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/21-02/1017/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/15-02/1029/', '/MS data DSSG/02-2022/04-02/1054/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/20-02/1037/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/22-02/1046/', '/MS data DSSG/01-2022/02-01/1044/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/22-02/1046/', '/MS data DSSG/01-2022/02-01/1047/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/22-02/1046/', '/MS data DSSG/01-2022/09-01/1019/')\n",
      "noam: 0 yaara: 1 omer: 0\n",
      "('/MS data DSSG/02-2022/22-02/1046/', '/MS data DSSG/01-2022/05-01/1042/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/22-02/1046/', '/MS data DSSG/01-2022/20-01/1027/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/22-02/1046/', '/MS data DSSG/02-2022/15-02/1029/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/07-02/1027/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/01-2022/10-01/1014/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/01-2022/03-01/1099/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/01-2022/18-01/1081/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/01-2022/20-01/1041/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/02-2022/24-02/1017/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/02-2022/04-02/1017/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/02-2022/10-02/1002/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/02-2022/10-02/1032/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/02-2022/21-02/1017/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/02-2022/20-02/1037/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/16-02/1024/', '/MS data DSSG/02-2022/07-02/1027/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/17-02/1038/', '/MS data DSSG/01-2022/06-01/1004/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/17-02/1038/', '/MS data DSSG/01-2022/05-01/1048/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/17-02/1038/', '/MS data DSSG/01-2022/18-01/1085/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/17-02/1038/', '/MS data DSSG/01-2022/25-01/1005/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/17-02/1038/', '/MS data DSSG/02-2022/08-02/1030/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/06-02/1002/', '/MS data DSSG/01-2022/03-01/1076/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/02-2022/06-02/1002/', '/MS data DSSG/01-2022/23-01/1011/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/03-2022/20-03/1073/', '/MS data DSSG/03-2022/31-03/1074/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/03-2022/24-03/1092/', '/MS data DSSG/03-2022/31-03/1074/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/03-2022/24-03/1000/', '/MS data DSSG/02-2022/24-02/1007/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/03-2022/23-03/1018/', '/MS data DSSG/03-2022/31-03/1074/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/03-2022/04-03/1021/', '/MS data DSSG/01-2022/10-01/1018/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/03-2022/04-03/1021/', '/MS data DSSG/02-2022/16-02/1024/')\n",
      "noam: 0 yaara: 0 omer: 1\n",
      "('/MS data DSSG/03-2022/29-03/1042/', '/MS data DSSG/03-2022/31-03/1074/')\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "np_omer_matrix = np.array(omer_cluster_matrix)\n",
    "np_yaara_matrix = np.array(yaara_cluster_matrix)\n",
    "np_noam_matrix = np.array(noam_cluster_matrix)\n",
    "tensor_method = np.stack([np_omer_matrix, np_yaara_matrix, np_noam_matrix])\n",
    "tensor_sum = np.sum(tensor_method, axis=0)\n",
    "print(tensor_sum)\n",
    "# interesting_samples = np.where((tensor_sum == 1) | (tensor_sum == 2))[0]\n",
    "# print(interesting_samples)\n",
    "samples_np = np.array(samples_matrix)\n",
    "interesting_samples = samples_np[(tensor_sum == 1) | (tensor_sum == 2)]\n",
    "# print(interesting_samples.shape)\n",
    "\n",
    "similar = 0\n",
    "for i in range(50):\n",
    "    for j in range(50):\n",
    "        if tensor_sum[i][j] == 1 and i > j:\n",
    "            print(\"noam:\", noam_cluster_matrix[i][j], \"yaara:\", yaara_cluster_matrix[i][j], \"omer:\", omer_cluster_matrix[i][j])\n",
    "            print(samples_matrix[i][j])\n",
    "            # for sample in samples_matrix[i][j]:\n",
    "            #     tic_front_path = sample[1:] + 'tic_front.csv'\n",
    "            #     data = pd.read_csv(tic_front_path, names=['x', 'y']).iloc[1:]\n",
    "            #     title_name = sample[1:].split('/')\n",
    "            #     title_ = \"pair: \" + str(similar) + \", sample: \" + title_name[2] + \"/\" + title_name[3]\n",
    "            #     data.plot(x='x', y='y', title=title_)\n",
    "            #     plt.show()\n",
    "            similar += 1\n",
    "print(similar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
